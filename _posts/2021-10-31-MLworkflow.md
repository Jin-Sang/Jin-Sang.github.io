---
layout: single
title:  "ML Workflow"
font-size: 5
use_math: true

---
# Deep Learning
<br/>


![workflow](https://user-images.githubusercontent.com/80252681/139578252-ede5829c-4c46-4b35-a957-c85156998b9d.png)



# **머신러닝의 작업흐름**&#128113;
---
여기서 다루는 내용은 크게 다음과 같은 단계로 나뉜다.

* 머신러닝 문제의 틀을 형성하는 것에 관한 단계
* 작동 모델을 발전시키는 것에 관한 단계
* 모델을 출시하고 유지시키는 것에 관한 단계


지금까지는 주어진 준비된 데이터셋을 이용하였지만, 실제로 머신러닝을 이용하여 문제를 해결하기 위한 프로젝트를 진행할 때는 데이터셋이 준비되어 있지 않다. 우리는 다양한 문제를 해결해 나가야한다. 머신 러닝 회사를 차리고, 홍보를 하는 등 다양한 문제를 해결한 후에야 프로젝트들이 주어진다.

* 다양한 머신러닝 프로젝트 : 사진들에서 특정 사진들만 검색하기, 스팸문자 표시하기, 음악 리스트 추천하기, 불량 쿠키를 판별하기, 신용카드 불법사용 감별하기 등등 


## **윤리적인 부분**&#128205;

머신 러닝 프로젝트를 진행함에 있어서 윤리적인 문제를 맞닥뜨리게 된다.

먼저, 주어진 프로젝트가 과연 타당성이 있는가? 효용성이 있는가? 하는 문제이다. 문제 자체에 대한 근본적인 질문이다. 문제 자체가 의미가 없을 수도 있다.  

두번째로는, 개발자의 고의적이든 고의적이지 않든 주관적인 의견이 포함될 수 밖에 없다는 것이다. 모든 기술은 중립적일 수 없다. 예를 들어 데이터를 수집하는 과정에서 조심을 하더라도 개발자의 주관이나 편견이 개입될 수 밖에 없다. 개발자가 데이터를 수집하는 과정에서 주관이 개입되기 때문이다. 

## **일반적인 작업흐름 3단계**&#128064;

1. **작업 정의하기** : 문제 또는 고객의 요구 이해, 데이터셋 수집, 데이터 이해, 성공 측정 방법 선택
2. **모델 개발하기** : 머신러닝 모델에 사용될 데이터셋 준비, 모델 평가 방법과 기준선(최소한 달성해야할 목표치) 선택, 처음에는 과대적합이 발생할 정도로 훈련, 가능한 일반화 성능을 최대화하기 위한 규제와 모델 튜닝
3. **모델 배치하기** : 모델을 사용될 환경에 맞게 제공, 추가적인 데이터 수집( 다음 일반화 성능을 향상시키기위해)

순서 | 작업 
--- | --- 
1단계 | 작업 정의하기
2단계 | 모델 개발하기
3단계 | 모델 배치하기


# **1. 작업 정의하기**&#128221;
---
좋은 결과물을 내고 싶다면 하려는 것에 대한 깊은 이해가 필요하다. 왜 하는지, 모델 훈련을 어떻게 하며 어떤 결과를 필요로 하는지, 어떤 데이터를 사용할 수 있는지 등 작업 전반에 대한 깊은 이해를 바탕으로 해야 좋은 결과물을 만들어 낼 수 있다. 

## **1.1 문제의 틀 정의**&#128173;

이 단계에서 항상 명심해야할 질문들이 있습니다.

* `입력 데이터는 무엇인가?`, `예측하려는 것은 무엇인가?` 

-`데이터의 사용가능성은 제한적이다.`

* `어떤 유형의 머신러닝 작업인가?` 

-`머신러닝 방식이 최선이 아닐수도 있다. 전통적인 통계학적 방법이 더 적절할 수도 있다.`

* `기존의 해결법은 무엇이며, 어떻게 작동하는가?`

-`이미 기존의 해결법을 가진 문제들이 많다. 그 해결법들을 파악하는 것이 큰 도움이 된다.`

* `고려해야 할 특정 제약들이 존재하는가?` 

-`특정 하드웨어와의 관계 또는 훈련이 이루어질 기기 등 특정 문제마다 다른 전체적인 환경을 이해해야한다.`

이 단계에서는 다음과 같은 가설을 기본으로 가지고 있다.

* `타겟 값은 주어진 입력값으로 예측되어 질 수 있다.`
* `사용가능한 데이터 혹은 곧 수집할 데이터들은 모델이 학습할 입력값과 예측값 사이에 충분히 유의미한 관계가 있다.`

하지만, 이것은 단지 가설일 뿐이다. 실제로 타당성이 있는지 없는지는 모델이 훈련되어 봐야 안다. 사실 모델은 입력값과 예측값 사이를 단지 조립할 뿐이다. 따라서 이것으로 실제로 입력값이 예측값에 대한 유의미한 정보를 갖는다고 말할 수 없다.

## **1.2 데이터 수집** &#128196;

문제의 본질 대한 이해가 끝났다면 이제는 데이터를 수집할 시간이다. 이 작업은 몹시 힘들고, 시간도 많이 걸리고, 비용도 많이 드는 부분이다. 

* `각각의 프로젝트들마다 적절한 그리고 가능한 방법으로 데이터셋을 수집하고, 그에 맞는 레이블을 붙여 줍니다.`

모델의 일반화 성능은 전적으로 데이터셋의 성질 및 특성(개수, 신뢰성, 양질의 특성 등)에 의존합니다. 그래서 좋은 데이터셋을 수집하는데 각별한 신경과 노력을 들일 필요가 있습니다.

* `알고리즘보다 데이터가 더 중요하다.` `-The Unreasonable Effectiveness of Data-` 

딥러닝 이전부터 신뢰받는 의견이었지만, 딥러닝의 등장은 이것을 더 입증해주었습니다.

### **레이블 붙여주기** &#9997;

지도 학습의 경우에는 데이터를 수집하고 그에 해당하는 **레이블**을 붙여주어야합니다. 자동으로 붙어있는 경우도 있지만, 대부분 직접 손으로 해야하는 매우 힘든 작업입니다.

레이블을 붙여주는 작업은 모델의 성능과도 직결되는 문제이기 때문에 매우 중요한 작업입니다. 레이블을 붙여주는 작업은 다음을 고려 할 수 있습니다.

* `직접 손으로 하나하나 레이블 달기`
* `쉽게 접근할 수 있는 공개된 레이블 달아주는 플랫폼 사용하기`
* `전문적인 회사에게 의뢰하기`


공개된 플랫폼을 사용하는 것은 시간과 비용을 많이 아껴줄 수는 있지만, 데이터에 잡음이 포함될 수 있습니다.

어떤 방식을 골라야 할 때 고려해야 할 사항은 다음과 같습니다.

* `레이블을 붙이는 사람이 전문가여야 하는가? 아니면 누구나 할 수 있는 일인가?`
* `레이블을 붙이는 것에 특별한 지식이 필요한가? 필요하다면 훈련시킬 수 있는지, 전문가에게 도움을 요청해야하는지`
* `전문가가 제안하는 방식을 이해할 수 있는가?`
 

직접 손으로 레이블을 붙여 줄 때 편리한 소프트웨어를 개발한다면 시간을 아끼는데 큰 도움이 될 것이다.

### **대표성없는 데이터** &#9984;

머신러닝 모델은 입력값을 자신이 이전에 보았던 것과 얼마나 유사한가를 바탕으로 이해하기 때문에 훈련 데이터는 실전에서 작업을 수행 할 일반 데이터에 대해 대표성을 가지고 있어야 한다. 그것이 모든 데이터 수집 작업에서 근간이 되어야 한다. 

훈련 데이터가 대표성이 없다면, 훈련데이터에 대한 성능은 뛰어나지만, 일반화 성능이 매우 떨어지는 모델이 만들어진다.

데이터 수집은 모델이 사용될 곳에서부터 수집하는 것이 가장 좋다. 만약 그럴 수 없다면 훈련을 어떻게 할지에 관해서 완전히 이해하고 훈련 데이터와 실제 사용될 데이터와의 차이를 이해하고 적극적으로 수정해주는 것이 좋다.

* `Concept Drift` : 실세계에서는 시간의 흐름에 따라 데이터는 변화한다. 그래서 그에 따라 모델의 성능도 떨어진다. 그래서 지속적으로 데이터 수집, 레이블 붙이기, 재훈련이 필요하다. 

**명심하라. 머신러닝은 훈련데이터의 패턴을 기억할 뿐이다. 모델은 미래를 예측하는데 그것이 과거와 비슷하게 일어날 것이라는 가정을 바탕으로 추측할 뿐이다.**

### **데이터 샘플링 편향** &#128533;


**`Sampling Bias`** : 대표성 없는 데이터의 흔한 예, 데이터 수집 과정에서 일어나는 현상이다. 개발자가 어떤 값을 예측하려하고 어떤 편향된 결과를 원하므로 그러한 편향이 데이터 수집 과정에 개입되어진다. 

대표적인 예 : `DEWEY DEFEATS TRUMAN` 전화 설문조사

## **1.3 데이터 이해**  &#128574;

모델을 훈련하기 전에 데이터에 대한 이해는 매우 중요하다. 데이터에 대한 통찰을 얻기 위해 데이터를 시각화하거나 연구해보는 것은 중요하다.

방법 : 이미지 확인, 히스토그램, 지도에 표시, null값 확인, 각각 클래스에 해당하는 샘플 수 확인 등

* `Target leak` : 실전에서 사용 될 수 있는 특성인지, 타겟이 데이터 특성에 개입되어 있는지 확인해야 한다.

## **1.4 모델의 성능 성공에 대한 측정 방식 선택** &#128588;

모델 성능의 성공 여부를 확인하고 측정하고 모델을 조절해나가기 위해서는 어떤 것을 성공의 측정치로 할 것인지 정의해야 한다. 그것에 따라 모델의 방향이 정해지는고 직접적인 영향을 준다.

* `accuracy`, `precision`, `recall` 등 다양한 문제에 다양한 metrix(지표)들이 있습니다. 직접 정의 할 수 도 있다.

# **2. 모델 개발하기** &#128526;
---
이제 어떻게 할지 알았다면, 이제 모델 개발을 할 차례다. 이 단계는 앞의 단계보다 쉬운 단계이다. 

## **2.1 데이터 준비하기** &#127793;


머신러닝 모델은 일반적으로 데이터를 있는 그대로 바로 받아들일 수 없다. 신경망에 더 잘 맞도록 전처리 과정이 필요하다.


전처리 기술은 특정 데이터마다 다르므로 여기서는 일반적인 데이터들에 대해 가능한 전처리 기법을 살펴본다.

* `Vectorization(벡터화)` : 모든 데이터를 텐서(일반적으로 float32형)로 만들어 주어야 한다.



* `Value Normalization(정규화)` : 일반적으로 큰 값을 가지는 특성은 모델에 좋지 않다고 알려져있다. 모델이 점점 수렴해서 만들어지는 것을 방해하기 때문이다.  

-`데이터의 특성값들은 다음 속성을 가져야 한다.`
1. `작은 값을 가질 것 - 일반적으로 대부분의 값들은 0과 1사이에 있어야한다.`
2. `각 특성값들은 단일적 일 것 - 모든 특성값들은 대략 같은 범위에 있어야 한다.`  

-`필수는 아니지만 엄격한 정규화가 도움이 될 수 도 있다.`
1. `각각의 특성값이 독립적으로 평균은 0인 정규분포를 따르게 한다.`
2. `각각의 특성값이 독립적으로 표준편차가 1인 정규분포를 따르게 한다.`

* `Handling Missing Values(결측치 다루기)` : 특성값 중 몇몇의 샘플에서 null값이 존재한다면 처리를 해주어야 한다. 완전히 그 특성을 버릴수도 있지만 반드시는 아니다.

-`그 특성이 범주형이라면, '값이 없음'이라는 범주를 추가해줄 수 있다`


-`그 특성이 숫자형이라면, 평균값, 중간값 등의 특성값들과 연관된 값을 넣을수 있다. 다른 특성을 사용할 수도 있다. 하지만 임의로 값을 정해서 넣어서는 안된다. 임의로 잠재된 가능성을 주기 것이기 때문이다.`

만약 테스트 데이터에는 결측값이 있을 것으로 예상되는데, 훈련 세트에는 없다고 판단된다면 임의로 훈련세트를 이용하여 그 데이터에 결측치를 채워주는 방법도 있다.

## **2.2 평가 방법 선택하기**  &#127856;

모든 모델은 일반화 성능을 달성하는 것이 목적이다. 보통 검증세트를 이용하여 이 선택한 평가 방법 즉, 지표를 이용하여 일반화 성능을 향상 시키는 것이 방법이다.
 

* `홀드아웃 검증세트` : 데이터 양이 충분히 많을 때
* `K-폴드 교차 검증` : 홀드아웃을 하기에 데이터 양이 충분하지 않을 때
* `반복된 K-폴드 검증` : 데이터양이 너무 적을 때 매우 정확한 모델 평가를 할 때 

검증세트도 마찬가지로 대표성을 가지고 있어야 한다. 그리고 훈련세트와 검증 세트에 불필요한 샘플들을 주의하자.

## **2.3 기준선 넘어서기** &#127881;

처음 모델을 개발시키고 훈련할 때 첫 번째 목표는 일반적으로 통계적 성능(`Statistical Power`)을 넘어서는 것이 먼저다. 그것을 `baseline`이라고 한다.

이 단계에서 중요한 3가지가 있다.

* `특성 공학` : 유익하지 않은 특성을 걸러낸다 즉, 특성 선택 그리고 유용할 것같은 특성을 발전 시킬 수 도 있다.
* `먼저 알맞은 모델 구조 선정하기` : 어떤 유형의 딥러닝 모델 구조를 사용할 것인지, 혹은 이것이 딥러닝으로 해결하는 것이 적절한지 검토한다.
* `알맞은 훈련 구성 선택하기` : 예를 들어 손실함수와 배치사이즈 등을 선정한다. 

### **알맞은 손실함수 선택하기** &#128020;


`metric(지표)`를 바로 최적화 시킬 수는 없다. 즉, 위에서 선택한 평가 방법을 한번에 최대한 좋게 만들 수는 없다는 말이다. 그리고 지표를 그대로 손실함수로 사용할 수 없는 경우가 많다. 그 이유는 손실함수의 다음과 같은 조건 때문이다.

* `손실함수는 한 개의 미니 배치에 대해서도 손실값을 계산할 수 있어야 한다.`
* `손실함수는 반드시 미분 가능해야 한다. 이것을 이용해 역전파를 이용해 신경망을 훈련시키기 때문이다.`

손실 함수가 대리 지표로 인식되기도 하는데, 이 때 대리 지표인 손실 함수가 최적화가 될 수록, 실제 지표(metric)도 최적화 되어 간다고 생각할 수 있다.

다음은 `문제의 유형 - 출력층 활성화함수 - 손실 함수` 의 일반적인 예를 보여준다.

* `이항분류 - sigmoid - binary_crossentropy`
* `다중클래스 싱글레이블 분류 - softmax - categorical_crossentropy`
* `다중클래스 다중레이블 분류 - sigmoid - binary_crossentropy`
* `임의의 값 회귀 - none - mse`

대부분의 문제들의 경우 당신이 처음 그 문제를 해결하려는 사람이 아닐 것이다. 이미 먼저 고민하고 연구한 사람들이 만들어 놓은 틀이 있다. 그러므로 먼저 조사를 하고 이해해라. 어떤 특성 공학 기술과 모델 구조가 사용 되었는지를 중심으로 파악하라. 

항상 베이스라인을 넘어서는 것에 성공하는 것은 아니다. 여러번의 합리적인 시도 이후에도 달성하지 못했다면 투입한 데이터에 적절한 상관성이 없는 것이다.

우리는 두 가지 가설을 전제로 모델을 개발한다.

* `출력값은 투입값으로 예측 되어 질수 있다.`
* `출력값과 입력값 사이에 관계는 모델이 학습 할 수 있을 정도로 충분히 정보가 담겨있다.` 

하지만 이 가설은 항상 옳진 않다. 거짓일 경우에는 다시 과감히 돌아서서 처음부터 시작해야 한다.

## **2.4 Scale up 확장하라 : 모델을 과대적합 시키기** &#128074;

먼저 베이스라인의 성능을 달성 했다면 이제는 충분히 효과적인 모델을 만들어야 한다.
* 머신러닝의 훈련에서 최적화와 일반화 사이에는 아슬아슬한 관계가 있다.
* 좋은 모델은 과소적합과 과대적합의 경계, 능력과잉과 능력부족 사이에 있는 모델이다. 


그러기 위해서는 그 경계를 알아야 한다.
 그러려면 먼저 그 선을 넘어야 한다. 

얼마나 큰 모델이 필요한지 알기 위해 과대 적합 모델을 만들 필요가 있고 그 방법은 다음과 같다.

* `Layer 수 늘리기`
* `Layer를 더 크게 만들기`
* `더 많은 epoch를 훈련시키기`

훈련 세트와 검증 세트의 `loss 값`과 `metric 값`을 항상 관찰해라. **검증 세트에 대한 값들의 결과가 나빠지기 시작하는 순간**, 모델은 **과대적합** 된다.

## **2.5 모델을 규제하고 튜닝하기** &#128170;

베이스 라인을 달성하고 과대 적합까지 만들어 냈다면 잘 하고 있는 것이다. 다음 목표는 일반화의 성능을 최대화 하는 것이다.

이제부터 엄청나게 많은 시간을 들여야 한다. 반복적으로 모델을 조정하고, 훈련하고, 검증세트를 이용해 평가한다. 모델이 가능한 최대한 좋아질 때까지 이 과정을 반복한다. 평가할 때 절대 테스트세트가 아닌 검증세트를 이용함에 주의해야한다. 시도해야 할 몇가지는 다음과 같다.

* `다른 구조의 시도. 층을 추가 또는 삭제`
* `드랍아웃 추가`
* `모델이 작을 때 L1 또는 L2 규제`
* `최적의 구조를 찾기 위해 다른 하이퍼파라미터(층에서 유닛수, 학습률 등) 사용`
* `선택적으로 데이터 지속적 관리, 특성 공학, 데이터를 더 모으고, 더 나은 특성 개발 및 필요없는 특성 삭제`

*이러한 일을 자동화해주는 소프트웨어가 있다. `(automated hyperparameter tuning software)`

주의하라. 검증 세트를 이용한 모델의 튜닝은 모델에 검증 세트에 대한 정보가 유입될 수 있다. 적은 수의 반복은 큰 문제가 없겠지만, 많은 수의 반복은 모델이 검증 세트에 대해 과대적합을 하도록 할 수 있다. 그러면 더 이상 검증세트를 이용한 성능 평가의 값을 신뢰할 수 없게 된다.

만족할만한 모델 구성을 찾았다면, 이제 훈련세트와 검증세트를 모두 이용해서 훈련하는 최종 모델을 훈련시킬 수 있다. 그리고 테스트 세트를 이용한 최종 평가를 하게 된다.
 

이 때 만약 테스트 세트에 대한 성능이 검증 세트에 대한 성능에 비해 현격히 나쁠 경우 2가지 상황을 생각할 수 있다.
* `검증 과정이 전혀 신뢰할 수 없다.`
* `검증 세트에 대해 과대적합이 일어났다.`

이런 경우 다른 검증 세트를 이용한 평가 방법을 생각해 볼 수 있다.

# **3. 모델 배치하기** &#128083;
---
테스트 세트에 대한 성능이 만족스럽다면 이제는 실전에 배치할 단계이다.

## **3.1 사용자에게 설명과 기대치 설정** &#128073;

모델을 성공적으로 만들었다면, 이제는 사용자의 기대치를 적정하게 설정시켜주는 것 또한 중요한 문제이다. 비전문가들은 모델이 인간과 같이 작업을 이해하고 문맥을 통해 이해한다고 오해할 수 있다. 그래서 실패의 경우( 잘못된 샘플과 잘못된 분류 등)들을 보여주면서 이것을 설명할 수 있다. 

모델은 인간이 만들어낸 레이블을 근사하도록 훈련되었기 때문에 인간 수준의 성능을 내기는 거의 불가능하다. 따라서 정확하게 모델의 성능을 설명할 필요가 있다. 오해를 불러일으키지 않도록 긍정적인 부분(예 : 정확도 98%)을 말하기 보다는 **부정적인 부분(예 : 잘못된 분류 5%)**을 말하는 것이 실제 작업 목표에 대한 성능을 이해시키는 데에 더 분명하다. 

사용자와 상의하여 핵심 런칭 결정 사항들을 결정해야한다. 예를들면 확률임계값 같은 것이다. 이러한 결정들은 트레이드오프 관계가 있기에 사용될 실전 상황에 대한 깊은 이해가 필요하다.

## **3.2 추론 모델 옮기기** &#128161;

드물게 훈련된 모델이 훈련으로 끝나지 않고 바로 훈련되고 조정된 모델이 실전에 투입되어야 할 때가 있다. 

**첫째,** 파이썬이 아닌 다른 환경으로 모델을 추출할 필요가 있을 때 이다.
* `실전 환경에서 파이썬을 지원하지 않을 때`
* `앱의 나머지 부분이 파이썬이 아닐 때, 오버헤드를 불러일으킬 수 있다.`


**둘째,** 모델을 훈련을 위함이 아니라 예측값을 추정하기 위함이다. 따라서 다양한 최적화(훈련)을 수행할 공간을 위해 추출 해 옮길 수도 있다. 

사용 가능한 배치 옵션들을 살펴 보자

### **REST API로 모델을 배치하기** &#128295;

실전에 배치하는 가장 흔한 방법이다. 서버나 클라우드 객체에 TensorFlow를 설치하고 REST API를 통해 모델의 예측을 질의한다. 

* `Flask`(파이썬 웹 배치 라이브러리)를 이용하여 자체앱을 만들거나,
*  API로 케라스 모델을 옮겨주는 `TensorFlow`의 자체 라이브러리 `TensorFlow Serving`를 사용할 수 있다.

이 배치 방법을 사용해야 할 경우는 다음과 같다.

* `모델의 예측을 사용하는 어플리케이션이 인터넷에 신뢰할만한 접근을 할 때 (인터넷이 없는 곳에서는 사용이 불가능 하다.)`
* `엄격한 시간 지연을 요청하지 않을 때 (요청, 추론, 응답 과정이 500밀리초정도걸린다.)`
* `입력 데이터가 너무 까다롭지 않을 때 (모델에 보여져야 하기 때문에 데이터는 해독된 형태로 서버에서 사용되어야 할것이다. 그리고 HTTP 요청 응답을 위해서는 SSL 암호화를 사용해야 한다. )`

이미지검색 엔진, 음악리스트 추천, 신용카드 불법사용 탐지 등의 프로젝트에 적합하다.

REST API를 이용할 때 중요한 질문이 있다.

* `직접 스스로 코드를 다 짤 것인가`
* `완전히 관리해주는 3자 클라우드 서비스(예 : Google product)를 이용할 것인가`

만약 Cloud AI Platform을 이용하면 모델을 Google Cloud Storge에 쉽게 업로드하게 해주고 그 모델을 질의하는 API를 제공한다. 이것은 많은 세세한 부분을 쉽게 다뤄준다.

### **기기에 모델을 배치하기** &#128295;


때론 만든 모델을 사용하는 어플리케이션이 운영되는 기기에 직접 모델을 배치해야할 때도 있다.  

이 배치 방법을 사용해야 할 경우는 다음과 같다.

* `모델이 엄격한 지연시간 또는 인터넷 연결이 좋지 못한 환경을 요청할 때 (증강 현실 어플리케이션에서는 서버에 원격 요청하여 작동하는 것은 성공 할 수없다.) `
* `모델이 메모리와 전력으로 부터 제한을 받지 않을만큼 충분히 작을 때`
* `가능한 높은 정확도를 얻는 것이 집중적이지 않을 때 (실행시간 효율성과 정확도는 트레이드 오프관계에 있기 때문에 큰 정확도를 요구하지 않는다면 기기에 직접 배ㅣ할 수도 있다. 메모리와 전력 제한은 큰 GPU를 이용해서 만든 최고의 모델만큼의 성능이 필요 없는 모델을 기기로 옮기게 만든다.)`
* `입력 데이터가 원격 서버로부터 해독 해서는 안될만큼 까다롭게 되어 있을 때` 

문자에서 스팸을 구분하는 프로젝트는 휴대폰 끼리의 암호화 되어있으므로, 이 배치를 사용해야한다.

스마트폰이나 임베비드 기기에 배치할 때 `TensorFlow Lite`를 사용하는 것이 도움이 될 수 있다.

### **브라우저에 배치하기** &#128295;

딥러닝은 desktop-based 또는 browser-based 자바스크립트 응용프로그램에서 사용될 수있다. **사용자 컴퓨터의 브라우저에 모델을 배치**한다는 점에서 REST API 배치를 하는 것에 장점이 있다. REST API는 원격 모델에게 질의를 통해 이용하는 반면 브라우저 배치는 사용자컴퓨터를 사용하므로 GUP 자원을 사용할 수 있다는 장점이 있다.  

이 배치 방법을 사용해야 할 경우는 다음과 같다.

* `서버의 부담을 줄일 수 있게 사용자 컴퓨터에 부담을 내리려는 때`
* `입력데이터가 사용자 컴퓨터에서 지속적으로 유지될 필요가 있을 때`
* `엄격한 지연 시간에 대한 지연이 있을 때`
* `모델이 한번 다운로드되거나 캐쉬 된 후에 연결이 더 이상 필요없을 때`


이 옵션은 모델이 충분히 작을 때 가능하다. 모델이 CPU, GPU, RAM과 같은 자원을 독차지 하지 않아야 한다.


한 번 딥러닝 모델이 다운되면 비밀스럽게 유지할 필요가 없다. 입력 데이터에 대한 정보는 회복 가능하므로, 까다로운 데이터에 대해 완전히 훈련한 모델을 배포하기 보다는 일단 모델을 받았다면 은밀하게 유지할 필요가 없다.

`TensorFlow.js`로 케라스 모델을 배치 시킬 수 있다. 

### **추론 모델 최적화** &#128296;

제한된 실전 환경(전력, 메모리양, 지연시간 제한 등)에서 모델을 최적화하는 것은 매우 중요하다.

따라서 배치를 하기 전에 최적화하기 위해 노력해야한다.

최적화 하기 위해서는 다음과 같은  두가지 방법이 있다.
* `가중치 축소(가지치기)` : 모든 가중치들이 동일한 기여를 하는 것이다. 따라서 많은 수의 파라미터들을 줄여서 메모리와 계산에 차지하는 공간을 줄일 수 있다. 하지만 성능과 파라미터 수 사이에 트레이드 오프 관계에 유의해야 한다.

* `가중치 양자화` : `flaot32` 가중치를 `int8`가중치로 바꿀 수 있다. 추론 모델의 크기는 4배 줄어들지만, 비슷한 성능을 가질수 있다.



TensorFlow ecosystem은 위의 작업을 할 수 있는 toolkit을 제공한다.

## **3.3 실전에서 모델을 관찰하기** &#128202;

추론 모델을 가져와서 앱으로 통합하고 간단히 시범 운영을 해보았는데 예상한 결과가 나왔다면 그리고 단위 테스트까지 했다면, 완벽하다. 이제 실전에 배치할 시간이다. 

하지만 배치만 하면 끝나느 것이 아니다. 이제 실전에서 그 모델이 어떻게 하는지 관찰해야 한다. 어떻게 작동하는지, 새로운 데이터에 어떻게 하는지, 앱의 다른 부분들과는 어떤 상호작용을하는지, 결과적으로 전체 성능에 어떤 영향을 주는지 등을 관찰해야한다.

* `바뀐 모델이 실전에서 큰 효과를 보는지 확인한다. 무작위 A/B 테스트를 통해 구 모델과 새로운 모델의 변화의 효과를 알아 볼수 있다. A, B 두개의 부분 데이터셋으로 나눠서 하나는 구모델 하나는 신모델에 적용 해보는 것이다.` 

* `정기적인 수동 검사` : 같은 데이터에 대해 모델의 예측값과 직접 손으로 레이블을 달아준 것을 비교하는 것 

* `정기적인 수동 검사가 불가능 할 때` : 사용자 설문조사와 같은 대체적인 방법을 사용할 수 있다.

## **3.4 모델을 유지하기**&#128227;	
영원한 모델은 없다. `concept drift`에 관해 배웠다. 시간이 지날수록 데이터의 특성은 변한다. 그에 따라 모델의 성능과 적절성도 하락한다. 따라서 모델의 수명도 제각각이다.

모델이 출시되자마자 바로 기존의 데이터를 대체할 다음 데이터 세대에 훈련할 준비를 해야한다.

* `실전데이터의 변화 관찰` : 새로운 데이터 특성이 사용가능한지, 레이블 세트를 수정해야하는지
* `새로운 데이터 수집과 레이블 달기` : 특히 현재 모델에서 잘 분류 못하는 데이터를 추가하면 모델 성능 향상에 도움이 된다.

# **요약** &#128269;	
---
각 순서대로 요약하였다.

## **직접 문제 정의**

* `전체적인 문맥에서 이해하기` : 최종목표, 제한사항
* `데이터를 모으고 레이블 붙이기` : 데이터세트에 대한 깊이있는 이해
* `성공을 측정할 지표 선택` : 관찰 할 검증세트에 대해 평가할 지표 선택


## **모델 개발**

* `데이터 준비`
* `평가방법 선택` : 어떤 검증 세트를 이용할지 선택
* `기준선 달성` : 통계적 수치 달성
* `과대적합 시키기`
* `규제 및 모델 튜닝` : 검증세트의 성능을 기반으로 하이퍼파라미터 규제

## **모델 배치**

테스트 세트에 대해 좋은 성능을 확인한 후 하는 작업이다.

* `사용자 기대치 설정`
* `추론 모델의 최적화 그리고 배치` : 실제로 사용할 환경에 배치 `ex 웹서버, 모바일, 브라우저, 임베비드 기기 등`
* `모델 관찰 및 다음 세대 데이터 수집` : 다음 세대에 대한 모델의 성능을 발전시킬수 있다. 
